{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "409f207e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.005705,
     "end_time": "2022-12-31T23:26:47.003050",
     "exception": false,
     "start_time": "2022-12-31T23:26:46.997345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this notebook we will train an `XGBoost Ranker` on the GPU and perform prediction.\n",
    "\n",
    "Training with varied architectures and ensembling (please see [ðŸ’¡ [2 methods] How-to ensemble predictions ðŸ…ðŸ…ðŸ…](https://www.kaggle.com/code/radek1/2-methods-how-to-ensemble-predictions) for a tutorial on ensembling) can offer you a significant jump on the LB!\n",
    "\n",
    "Training with `XGBoost` however offers more additional advantages. In comparison to `LGBM`, `XGBoost` allows you to train with the following objectives (`LGBM` gives you access to a single loss only for ranking, training with different objectives is a great way of improving your ensemble!):\n",
    "* `rank:pairwise`\n",
    "* `rank:ndcg`\n",
    "* `rank:map`\n",
    "\n",
    "On top of that, we will train on the GPU! ðŸ”¥ GPU can offer a significant speed-up. You can train more and bigger models in a shorter amount of time. However, when training on the GPU with large amounts of tabular data, you can easily run into problems (how to load the data onto the GPU for processing in chunks, how to manage memory).\n",
    "\n",
    "As we want to focus on feature engineering and training lets offload all the low level, tedious considerations to the `Merlin Framework`!\n",
    "\n",
    "In this notebook, we will introduce the entire pipeline. We will preprocess our data on the GPU using a library specifically designed for tabular data preprocessing, `NVTabular`. We will then proceed to train our `XGBoost` model with `Merlin Models`. In the background  we will leverage `dask_cuda` and distributed training to optimize the use of available GPU RAM, but we will let the libraries handle all that! No additional configuration will be required from us.\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "## Other resources you might find useful:\n",
    "\n",
    "* [ðŸ’¡ [2 methods] How-to ensemble predictions ðŸ…ðŸ…ðŸ…](https://www.kaggle.com/code/radek1/2-methods-how-to-ensemble-predictions)\n",
    "* [co-visitation matrix - simplified, imprvd logic ðŸ”¥](https://www.kaggle.com/code/radek1/co-visitation-matrix-simplified-imprvd-logic)\n",
    "* [ðŸ’¡ Word2Vec How-to [training and submission]ðŸš€ðŸš€ðŸš€](https://www.kaggle.com/code/radek1/word2vec-how-to-training-and-submission)\n",
    "* [local validation tracks public LB perfecty -- here is the setup](https://www.kaggle.com/competitions/otto-recommender-system/discussion/364991)\n",
    "* [ðŸ’¡ For my friends from Twitter and LinkedIn -- here is how to dive into this competition ðŸ³](https://www.kaggle.com/competitions/otto-recommender-system/discussion/368560)\n",
    "* [Full dataset processed to CSV/parquet files with optimized memory footprint](https://www.kaggle.com/competitions/otto-recommender-system/discussion/363843)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f687ae89",
   "metadata": {
    "papermill": {
     "duration": 0.004325,
     "end_time": "2022-12-31T23:26:47.012269",
     "exception": false,
     "start_time": "2022-12-31T23:26:47.007944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries installation\n",
    "\n",
    "We will need a couple of libraries that do not come preinstalled on the Kaggle VM. Let's install them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc947d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-31T23:26:47.023706Z",
     "iopub.status.busy": "2022-12-31T23:26:47.022908Z",
     "iopub.status.idle": "2022-12-31T23:28:32.440898Z",
     "shell.execute_reply": "2022-12-31T23:28:32.439545Z"
    },
    "papermill": {
     "duration": 105.427063,
     "end_time": "2022-12-31T23:28:32.443865",
     "exception": false,
     "start_time": "2022-12-31T23:26:47.016802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install nvtabular==1.3.3 merlin-models polars merlin-core==v0.4.0 dask_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa91d371",
   "metadata": {
    "papermill": {
     "duration": 0.004607,
     "end_time": "2022-12-31T23:28:32.453389",
     "exception": false,
     "start_time": "2022-12-31T23:28:32.448782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88af3845",
   "metadata": {
    "papermill": {
     "duration": 0.004341,
     "end_time": "2022-12-31T23:28:32.462353",
     "exception": false,
     "start_time": "2022-12-31T23:28:32.458012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will briefly preprocess our data using polars. After that step, we will hand it over to `NVTabular` to tag our data (so that our model will know where to find the information it needs for training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34983489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-31T23:28:32.474758Z",
     "iopub.status.busy": "2022-12-31T23:28:32.473773Z",
     "iopub.status.idle": "2022-12-31T23:28:36.371842Z",
     "shell.execute_reply": "2022-12-31T23:28:36.370861Z"
    },
    "papermill": {
     "duration": 3.907342,
     "end_time": "2022-12-31T23:28:36.374207",
     "exception": false,
     "start_time": "2022-12-31T23:28:32.466865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nvtabular import *\n",
    "from merlin.schema.tags import Tags\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "\n",
    "from merlin.core.utils import Distributed\n",
    "from merlin.models.xgb import XGBoost\n",
    "from nvtabular.ops import AddTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "528ee138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-31T23:28:36.384961Z",
     "iopub.status.busy": "2022-12-31T23:28:36.384678Z",
     "iopub.status.idle": "2022-12-31T23:28:48.568314Z",
     "shell.execute_reply": "2022-12-31T23:28:48.567159Z"
    },
    "papermill": {
     "duration": 12.19232,
     "end_time": "2022-12-31T23:28:48.571303",
     "exception": false,
     "start_time": "2022-12-31T23:28:36.378983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pl.read_parquet('../input/otto-train-and-test-data-for-local-validation/test.parquet')\n",
    "train_labels = pl.read_parquet('../input/otto-train-and-test-data-for-local-validation/test_labels.parquet')\n",
    "\n",
    "def add_action_num_reverse_chrono(df):\n",
    "    return df.select([\n",
    "        pl.col('*'),\n",
    "        pl.col('session').cumcount().reverse().over('session').alias('action_num_reverse_chrono')\n",
    "    ])\n",
    "\n",
    "def add_session_length(df):\n",
    "    return df.select([\n",
    "        pl.col('*'),\n",
    "        pl.col('session').count().over('session').alias('session_length')\n",
    "    ])\n",
    "\n",
    "def add_log_recency_score(df):\n",
    "    linear_interpolation = 0.1 + ((1-0.1) / (df['session_length']-1)) * (df['session_length']-df['action_num_reverse_chrono']-1)\n",
    "    return df.with_columns(pl.Series(2**linear_interpolation - 1).alias('log_recency_score')).fill_nan(1)\n",
    "\n",
    "def add_type_weighted_log_recency_score(df):\n",
    "    type_weights = {0:1, 1:6, 2:3}\n",
    "    type_weighted_log_recency_score = pl.Series(df['type'].apply(lambda x: type_weights[x]) * df['log_recency_score'])\n",
    "    return df.with_column(type_weighted_log_recency_score.alias('type_weighted_log_recency_score'))\n",
    "\n",
    "def apply(df, pipeline):\n",
    "    for f in pipeline:\n",
    "        df = f(df)\n",
    "    return df\n",
    "\n",
    "pipeline = [add_action_num_reverse_chrono, add_session_length, add_log_recency_score, add_type_weighted_log_recency_score]\n",
    "\n",
    "train = apply(train, pipeline)\n",
    "\n",
    "type2id = {\"clicks\": 0, \"carts\": 1, \"orders\": 2}\n",
    "\n",
    "train_labels = train_labels.explode('ground_truth').with_columns([\n",
    "    pl.col('ground_truth').alias('aid'),\n",
    "    pl.col('type').apply(lambda x: type2id[x])\n",
    "])[['session', 'type', 'aid']]\n",
    "\n",
    "train_labels = train_labels.with_columns([\n",
    "    pl.col('session').cast(pl.datatypes.Int32),\n",
    "    pl.col('type').cast(pl.datatypes.UInt8),\n",
    "    pl.col('aid').cast(pl.datatypes.Int32)\n",
    "])\n",
    "\n",
    "train_labels = train_labels.with_column(pl.lit(1).alias('gt'))\n",
    "\n",
    "train = train.join(train_labels, how='left', on=['session', 'type', 'aid']).with_column(pl.col('gt').fill_null(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41eaebe",
   "metadata": {
    "papermill": {
     "duration": 0.004355,
     "end_time": "2022-12-31T23:28:48.585034",
     "exception": false,
     "start_time": "2022-12-31T23:28:48.580679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us now define the preprocessing steps we would like to apply to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac95e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-31T23:28:48.596045Z",
     "iopub.status.busy": "2022-12-31T23:28:48.595024Z",
     "iopub.status.idle": "2022-12-31T23:28:50.876199Z",
     "shell.execute_reply": "2022-12-31T23:28:50.875253Z"
    },
    "papermill": {
     "duration": 2.289053,
     "end_time": "2022-12-31T23:28:50.878524",
     "exception": false,
     "start_time": "2022-12-31T23:28:48.589471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = Dataset(train.to_pandas())\n",
    "\n",
    "feature_cols = ['aid', 'type','action_num_reverse_chrono', 'session_length', 'log_recency_score', 'type_weighted_log_recency_score']\n",
    "target = ['gt'] >> AddTags([Tags.TARGET])\n",
    "qid_column = ['session'] >>  AddTags([Tags.USER_ID]) # we will use sessions as a query ID column\n",
    "                                                     # in XGBoost parlance this a way of grouping together for training\n",
    "                                                     # when training with LGBM we had to calculate session lengths, but here the model does all the work for us!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6477f4",
   "metadata": {
    "papermill": {
     "duration": 0.004424,
     "end_time": "2022-12-31T23:28:50.887742",
     "exception": false,
     "start_time": "2022-12-31T23:28:50.883318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Having defined the preprocessing steps, we can now apply them to our data. The preprocessing is going to run on the GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a176b603",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-31T23:28:50.898476Z",
     "iopub.status.busy": "2022-12-31T23:28:50.898171Z",
     "iopub.status.idle": "2022-12-31T23:28:50.958693Z",
     "shell.execute_reply": "2022-12-31T23:28:50.957826Z"
    },
    "papermill": {
     "duration": 0.06841,
     "end_time": "2022-12-31T23:28:50.960748",
     "exception": false,
     "start_time": "2022-12-31T23:28:50.892338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wf = Workflow(feature_cols + target + qid_column)\n",
    "train_processed = wf.fit_transform(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc27ae48",
   "metadata": {
    "papermill": {
     "duration": 0.005658,
     "end_time": "2022-12-31T23:28:50.970846",
     "exception": false,
     "start_time": "2022-12-31T23:28:50.965188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f93b322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-31T23:28:50.993728Z",
     "iopub.status.busy": "2022-12-31T23:28:50.993290Z",
     "iopub.status.idle": "2022-12-31T23:28:51.000142Z",
     "shell.execute_reply": "2022-12-31T23:28:50.998951Z"
    },
    "papermill": {
     "duration": 0.024214,
     "end_time": "2022-12-31T23:28:51.002482",
     "exception": false,
     "start_time": "2022-12-31T23:28:50.978268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ranker = XGBoost(train_processed.schema, objective='rank:pairwise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5532f83",
   "metadata": {
    "papermill": {
     "duration": 0.008463,
     "end_time": "2022-12-31T23:28:51.025717",
     "exception": false,
     "start_time": "2022-12-31T23:28:51.017254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The `Distributed` context manager will start a dask cudf cluster of us. A Dask cluster will be able to better manage memory usage for us. Normally, setting it up would be quite tedious -- here, we get all the benefits with a single line of Python code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b360e85b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-31T23:28:51.044699Z",
     "iopub.status.busy": "2022-12-31T23:28:51.044175Z",
     "iopub.status.idle": "2022-12-31T23:30:11.196948Z",
     "shell.execute_reply": "2022-12-31T23:30:11.195662Z"
    },
    "papermill": {
     "duration": 80.164901,
     "end_time": "2022-12-31T23:30:11.199627",
     "exception": false,
     "start_time": "2022-12-31T23:28:51.034726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "/opt/conda/lib/python3.7/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "[23:28:59] task [xgboost.dask-0]:tcp://127.0.0.1:34879 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-map:0.93747\n",
      "[1]\ttrain-map:0.93780\n",
      "[2]\ttrain-map:0.93820\n",
      "[3]\ttrain-map:0.93825\n",
      "[4]\ttrain-map:0.93830\n",
      "[5]\ttrain-map:0.93833\n",
      "[6]\ttrain-map:0.93841\n",
      "[7]\ttrain-map:0.93842\n",
      "[8]\ttrain-map:0.93844\n",
      "[9]\ttrain-map:0.93848\n"
     ]
    }
   ],
   "source": [
    "# version mismatch doesn't result in a loss of functionality here for us\n",
    "# it stems from the versions of libraries that the Kaggle vm comes preinstalled with\n",
    "\n",
    "with Distributed():\n",
    "    ranker.fit(train_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4618d",
   "metadata": {
    "papermill": {
     "duration": 0.008908,
     "end_time": "2022-12-31T23:30:11.217258",
     "exception": false,
     "start_time": "2022-12-31T23:30:11.208350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have now trained our model! Let's predict on test!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434138d1",
   "metadata": {
    "papermill": {
     "duration": 0.007189,
     "end_time": "2022-12-31T23:30:11.229736",
     "exception": false,
     "start_time": "2022-12-31T23:30:11.222547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a3d888",
   "metadata": {
    "papermill": {
     "duration": 0.005357,
     "end_time": "2022-12-31T23:30:11.245468",
     "exception": false,
     "start_time": "2022-12-31T23:30:11.240111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's load our test set, process it and predict on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd4cf8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-31T23:30:11.257657Z",
     "iopub.status.busy": "2022-12-31T23:30:11.257320Z",
     "iopub.status.idle": "2022-12-31T23:30:20.553869Z",
     "shell.execute_reply": "2022-12-31T23:30:20.552553Z"
    },
    "papermill": {
     "duration": 9.30544,
     "end_time": "2022-12-31T23:30:20.556396",
     "exception": false,
     "start_time": "2022-12-31T23:30:11.250956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pl.read_parquet('../input/otto-full-optimized-memory-footprint/test.parquet')\n",
    "test = apply(test, pipeline)\n",
    "test_ds = Dataset(test.to_pandas())\n",
    "\n",
    "wf = wf.remove_inputs(['gt']) # we don't have ground truth information in test!\n",
    "\n",
    "test_ds_transformed = wf.transform(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625608f0",
   "metadata": {
    "papermill": {
     "duration": 0.005326,
     "end_time": "2022-12-31T23:30:20.567683",
     "exception": false,
     "start_time": "2022-12-31T23:30:20.562357",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's output the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e61ec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-31T23:30:20.581526Z",
     "iopub.status.busy": "2022-12-31T23:30:20.579714Z",
     "iopub.status.idle": "2022-12-31T23:30:23.033822Z",
     "shell.execute_reply": "2022-12-31T23:30:23.032781Z"
    },
    "papermill": {
     "duration": 2.463075,
     "end_time": "2022-12-31T23:30:23.036370",
     "exception": false,
     "start_time": "2022-12-31T23:30:20.573295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds = ranker.booster.predict(xgb.DMatrix(test_ds_transformed.compute()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296c9f8",
   "metadata": {
    "papermill": {
     "duration": 0.005175,
     "end_time": "2022-12-31T23:30:23.047109",
     "exception": false,
     "start_time": "2022-12-31T23:30:23.041934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3984eee8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-31T23:30:23.059653Z",
     "iopub.status.busy": "2022-12-31T23:30:23.058803Z",
     "iopub.status.idle": "2022-12-31T23:30:24.026459Z",
     "shell.execute_reply": "2022-12-31T23:30:24.025449Z"
    },
    "papermill": {
     "duration": 0.976676,
     "end_time": "2022-12-31T23:30:24.029164",
     "exception": false,
     "start_time": "2022-12-31T23:30:23.052488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = test.with_columns(pl.Series(name='score', values=test_preds))\n",
    "test_predictions = test.sort(['session', 'score'], reverse=True).groupby('session').agg([\n",
    "    pl.col('aid').limit(20).list()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb90877b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-31T23:30:24.041658Z",
     "iopub.status.busy": "2022-12-31T23:30:24.041342Z",
     "iopub.status.idle": "2022-12-31T23:30:34.323002Z",
     "shell.execute_reply": "2022-12-31T23:30:34.320933Z"
    },
    "papermill": {
     "duration": 10.291495,
     "end_time": "2022-12-31T23:30:34.326452",
     "exception": false,
     "start_time": "2022-12-31T23:30:24.034957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "session_types = []\n",
    "labels = []\n",
    "\n",
    "for session, preds in zip(test_predictions['session'].to_numpy(), test_predictions['aid'].to_numpy()):\n",
    "    l = ' '.join(str(p) for p in preds)\n",
    "    for session_type in ['clicks', 'carts', 'orders']:\n",
    "        labels.append(l)\n",
    "        session_types.append(f'{session}_{session_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bba3a90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-31T23:30:34.340126Z",
     "iopub.status.busy": "2022-12-31T23:30:34.339817Z",
     "iopub.status.idle": "2022-12-31T23:30:36.977324Z",
     "shell.execute_reply": "2022-12-31T23:30:36.976166Z"
    },
    "papermill": {
     "duration": 2.647121,
     "end_time": "2022-12-31T23:30:36.980370",
     "exception": false,
     "start_time": "2022-12-31T23:30:34.333249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pl.DataFrame({'session_type': session_types, 'labels': labels})\n",
    "submission.write_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 240.457898,
   "end_time": "2022-12-31T23:30:39.910657",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-31T23:26:39.452759",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
