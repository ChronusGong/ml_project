{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efec955d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.009724,
     "end_time": "2023-03-20T03:14:56.277100",
     "exception": false,
     "start_time": "2023-03-20T03:14:56.267376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A co-visitation matrix is essentially an \"analog\" approximation to matrix factorization! I talk a bit more about this idea here: [ðŸ’¡ What is the co-visitation matrix, really?](https://www.kaggle.com/competitions/otto-recommender-system/discussion/365358).\n",
    "\n",
    "But matrix factorization has a lot of advantages as compared to co-visitation matrices. First of all, it can make better use of data -- it operates on the notion of similarity between categories. We can construct a more powerful representation if our model understands that aid `1` is similar to aid `142` as opposed to it treating each aid as an atomic entity (this is the jump from unigram/bigram/trigram models to word2vec in NLP).\n",
    "\n",
    "Let us thus train a matrix factorization model and replace the co-visitation matrices with it!\n",
    "\n",
    "Now, I don't expect that the first version of the model will be particularly well tuned. There has already been a lot of work put into co-visitation matrices and in the later versions we work off 3 different matrices, one for each category of actions! A similar progression can and will happen with matrix factorization ðŸ™‚ This notebook hopefully will enable us to jumpstart this type of exploration ðŸ™‚\n",
    "\n",
    "To streamline the work, we will use data in `parquet` format. (Here is the notebook [ðŸ’¡ [Howto] Full dataset as parquet/csv files](https://www.kaggle.com/code/radek1/howto-full-dataset-as-parquet-csv-files) and here is [the most up-to-date version of the dataset](https://www.kaggle.com/datasets/radek1/otto-full-optimized-memory-footprint), no need for dealing with `jasonl` files and the associated mess any longer! Please upvote if you find this useful!)\n",
    "\n",
    "For data processing we will use [polars](https://www.pola.rs/). `Polars` has a much smaller memory footprint than `pandas` and is quite fast. Plus it has really clean, intuitive API.\n",
    "\n",
    "Let's get to work! ðŸ™‚\n",
    "\n",
    "**UPDATE:** [@CPMP](https://www.kaggle.com/cpmpml) ported this notebook to run fully on the GPU! ðŸ¥³ This is awesome as it can allow you to experiment and ensemble models much faster ðŸ”¥ The other notebook also demonstrates how to accelerate a workflow very important to RecSys (and at the heart of the predictions in the notebook you are reading now) -- the nearest neighbor search algorithm. By running it on the GPU not only do you get significantly better results (you don't have to rely on approximate nearest neighbor search anymore, there is enough compute to develiver __true nearest neighbor search faster than you could run ANN on the CPU!__)\n",
    "\n",
    "Please find the GPU accelerated notebook here: [ðŸ’¡Matrix Factorization with GPU](https://www.kaggle.com/code/cpmpml/matrix-factorization-with-gpu)\n",
    "\n",
    "And if you would be interested in a further discussion of NN (nearest neighbor) vs ANN (approximate nearest neighbor) and running them the CPU/GPU, please see my post [here](https://www.kaggle.com/competitions/otto-recommender-system/discussion/371111) (though it is a bit outdated as `cuml` has a nicer API).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d57d92",
   "metadata": {
    "papermill": {
     "duration": 0.00833,
     "end_time": "2023-03-20T03:14:56.294624",
     "exception": false,
     "start_time": "2023-03-20T03:14:56.286294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc318018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:14:56.314455Z",
     "iopub.status.busy": "2023-03-20T03:14:56.313398Z",
     "iopub.status.idle": "2023-03-20T03:15:26.683887Z",
     "shell.execute_reply": "2023-03-20T03:15:26.682691Z"
    },
    "papermill": {
     "duration": 30.384182,
     "end_time": "2023-03-20T03:15:26.687387",
     "exception": false,
     "start_time": "2023-03-20T03:14:56.303205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "train = pl.read_parquet('/Users/chronus/Data/code/Git-repo/machine learning/data/train.parquet')\n",
    "test = pl.read_parquet('/Users/chronus/Data/code/Git-repo/machine learning/data/test.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9df21a",
   "metadata": {
    "papermill": {
     "duration": 0.008825,
     "end_time": "2023-03-20T03:15:26.705764",
     "exception": false,
     "start_time": "2023-03-20T03:15:26.696939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We need to create `aid-aid` pairs to train our matrix factorization model!\n",
    "\n",
    "Let's us grab the pairs both from the train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "067be2d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:15:26.727380Z",
     "iopub.status.busy": "2023-03-20T03:15:26.726626Z",
     "iopub.status.idle": "2023-03-20T03:16:16.962296Z",
     "shell.execute_reply": "2023-03-20T03:16:16.959694Z"
    },
    "papermill": {
     "duration": 50.267265,
     "end_time": "2023-03-20T03:16:16.982138",
     "exception": false,
     "start_time": "2023-03-20T03:15:26.714873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:2: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 4.72 s, total: 19.9 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_pairs = (pl.concat([train, test])\n",
    "    .groupby('session').agg([\n",
    "        pl.col('aid'),\n",
    "        pl.col('aid').shift(-1).alias('aid_next')\n",
    "    ])\n",
    "    .explode(['aid', 'aid_next'])\n",
    "    .drop_nulls()\n",
    ")[['aid', 'aid_next']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "252397cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:16:17.004152Z",
     "iopub.status.busy": "2023-03-20T03:16:17.003607Z",
     "iopub.status.idle": "2023-03-20T03:16:17.015811Z",
     "shell.execute_reply": "2023-03-20T03:16:17.014834Z"
    },
    "papermill": {
     "duration": 0.026502,
     "end_time": "2023-03-20T03:16:17.018803",
     "exception": false,
     "start_time": "2023-03-20T03:16:16.992301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209.072637"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs.shape[0] / 1_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b09e97c",
   "metadata": {
    "papermill": {
     "duration": 0.00914,
     "end_time": "2023-03-20T03:16:17.038326",
     "exception": false,
     "start_time": "2023-03-20T03:16:17.029186",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "That is 209 million pairs created in 40 seconds without running out of RAM! ðŸ™‚ Not too bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c6eba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:16:17.058746Z",
     "iopub.status.busy": "2023-03-20T03:16:17.058341Z",
     "iopub.status.idle": "2023-03-20T03:16:17.065337Z",
     "shell.execute_reply": "2023-03-20T03:16:17.064511Z"
    },
    "papermill": {
     "duration": 0.019867,
     "end_time": "2023-03-20T03:16:17.067622",
     "exception": false,
     "start_time": "2023-03-20T03:16:17.047755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>aid</th><th>aid_next</th></tr><tr><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>1590807</td><td>1228619</td></tr><tr><td>1228619</td><td>1590807</td></tr><tr><td>1590807</td><td>1590807</td></tr><tr><td>1590807</td><td>1590807</td></tr><tr><td>1590807</td><td>1590807</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ aid     â”† aid_next â”‚\n",
       "â”‚ ---     â”† ---      â”‚\n",
       "â”‚ i32     â”† i32      â”‚\n",
       "â•žâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 1590807 â”† 1228619  â”‚\n",
       "â”‚ 1228619 â”† 1590807  â”‚\n",
       "â”‚ 1590807 â”† 1590807  â”‚\n",
       "â”‚ 1590807 â”† 1590807  â”‚\n",
       "â”‚ 1590807 â”† 1590807  â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36056e7a",
   "metadata": {
    "papermill": {
     "duration": 0.008982,
     "end_time": "2023-03-20T03:16:17.085939",
     "exception": false,
     "start_time": "2023-03-20T03:16:17.076957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's see what is the cardinality of our aids -- we will need this to create the embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e32ec0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:16:17.106718Z",
     "iopub.status.busy": "2023-03-20T03:16:17.106233Z",
     "iopub.status.idle": "2023-03-20T03:16:17.313913Z",
     "shell.execute_reply": "2023-03-20T03:16:17.312871Z"
    },
    "papermill": {
     "duration": 0.221102,
     "end_time": "2023-03-20T03:16:17.316296",
     "exception": false,
     "start_time": "2023-03-20T03:16:17.095194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1855602"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinality_aids = max(train_pairs['aid'].max(), train_pairs['aid_next'].max())\n",
    "cardinality_aids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b46a60c",
   "metadata": {
    "papermill": {
     "duration": 0.008884,
     "end_time": "2023-03-20T03:16:17.334841",
     "exception": false,
     "start_time": "2023-03-20T03:16:17.325957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will have up to `1855602` -- that is a lot! But our matrix factorization model will be able to handle this.\n",
    "\n",
    "Let's construct a `PyTorch` dataset and `dataloader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d916e8de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:16:17.355978Z",
     "iopub.status.busy": "2023-03-20T03:16:17.355003Z",
     "iopub.status.idle": "2023-03-20T03:16:19.339437Z",
     "shell.execute_reply": "2023-03-20T03:16:19.338374Z"
    },
    "papermill": {
     "duration": 1.997916,
     "end_time": "2023-03-20T03:16:19.342205",
     "exception": false,
     "start_time": "2023-03-20T03:16:17.344289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ClicksDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.aid1 = pairs['aid'].to_numpy()\n",
    "        self.aid2 = pairs['aid_next'].to_numpy()\n",
    "    def __getitem__(self, idx):\n",
    "        aid1 = self.aid1[idx]\n",
    "        aid2 = self.aid2[idx]\n",
    "        return [aid1, aid2]\n",
    "    def __len__(self):\n",
    "        return len(self.aid1)\n",
    "\n",
    "train_ds = ClicksDataset(train_pairs[:-10_000_000])\n",
    "valid_ds = ClicksDataset(train_pairs[10_000_000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80d616",
   "metadata": {
    "papermill": {
     "duration": 0.008975,
     "end_time": "2023-03-20T03:16:19.360499",
     "exception": false,
     "start_time": "2023-03-20T03:16:19.351524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us see how quickly we can iterate over a single epoch with a batch size of `65536`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0284892f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:16:19.381460Z",
     "iopub.status.busy": "2023-03-20T03:16:19.380855Z",
     "iopub.status.idle": "2023-03-20T03:16:19.387352Z",
     "shell.execute_reply": "2023-03-20T03:16:19.386172Z"
    },
    "papermill": {
     "duration": 0.01966,
     "end_time": "2023-03-20T03:16:19.389794",
     "exception": false,
     "start_time": "2023-03-20T03:16:19.370134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = ClicksDataset(train_pairs)\n",
    "train_dl_pytorch = DataLoader(train_ds, 65536, True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "064aa0c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:16:19.411437Z",
     "iopub.status.busy": "2023-03-20T03:16:19.410925Z",
     "iopub.status.idle": "2023-03-20T03:28:08.036865Z",
     "shell.execute_reply": "2023-03-20T03:28:08.034952Z"
    },
    "papermill": {
     "duration": 708.654232,
     "end_time": "2023-03-20T03:28:08.053556",
     "exception": false,
     "start_time": "2023-03-20T03:16:19.399324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 44s, sys: 25 s, total: 3min 9s\n",
      "Wall time: 11min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for batch in train_dl_pytorch:\n",
    "    aid1, aid2 = batch[0], batch[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c275689b",
   "metadata": {
    "papermill": {
     "duration": 0.009502,
     "end_time": "2023-03-20T03:28:08.072665",
     "exception": false,
     "start_time": "2023-03-20T03:28:08.063163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Oh dear, that took forever! Mind you, were are not doing anything here, apart from iterating over the dataset for a single epoch (and that is without validation!).\n",
    "\n",
    "The reason this is taking so long is that indexing into the the arrays and collating results into batches is very computationally expensive.\n",
    "\n",
    "There are ways to work around this but they require writing a lot of code (you could use the iterable-style dataset). And still our solution wouldn't be particularly well optimized.\n",
    "\n",
    "Let us do something else instead!\n",
    "\n",
    "We will use a brand new [Merlin Dataloader](https://github.com/NVIDIA-Merlin/dataloader). It is a library that my team launched just a couple of days ago ðŸ™‚\n",
    "\n",
    "Now this library shines when you have a GPU, which is what you generally want when training DL models. But, alas, Kaggle gives you only 13 GB of RAM on a kernel with a GPU, and that wouldn't allow us to process our dataset!\n",
    "\n",
    "Let's see how far we can get with CPU only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b92b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:28:08.095013Z",
     "iopub.status.busy": "2023-03-20T03:28:08.094439Z",
     "iopub.status.idle": "2023-03-20T03:29:51.502467Z",
     "shell.execute_reply": "2023-03-20T03:29:51.501334Z"
    },
    "papermill": {
     "duration": 103.423357,
     "end_time": "2023-03-20T03:29:51.505514",
     "exception": false,
     "start_time": "2023-03-20T03:28:08.082157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting merlin-dataloader==0.0.2\r\n",
      "  Downloading merlin-dataloader-0.0.2.tar.gz (44 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting merlin-core\r\n",
      "  Downloading merlin-core-0.7.0.tar.gz (108 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-metadata>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from merlin-core->merlin-dataloader==0.0.2) (1.9.0)\r\n",
      "  Downloading merlin-core-0.6.0.tar.gz (108 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Downloading merlin-core-0.5.0.tar.gz (104 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.7/104.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from merlin-core->merlin-dataloader==0.0.2) (3.19.4)\r\n",
      "Requirement already satisfied: distributed>=2021.11.2 in /opt/conda/lib/python3.7/site-packages (from merlin-core->merlin-dataloader==0.0.2) (2022.2.0)\r\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from merlin-core->merlin-dataloader==0.0.2) (8.0.0)\r\n",
      "Requirement already satisfied: tqdm>=4.0 in /opt/conda/lib/python3.7/site-packages (from merlin-core->merlin-dataloader==0.0.2) (4.64.0)\r\n",
      "Requirement already satisfied: dask>=2021.11.2 in /opt/conda/lib/python3.7/site-packages (from merlin-core->merlin-dataloader==0.0.2) (2022.2.0)\r\n",
      "Requirement already satisfied: pandas<1.4.0dev0,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from merlin-core->merlin-dataloader==0.0.2) (1.3.5)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from merlin-core->merlin-dataloader==0.0.2) (21.3)\r\n",
      "Collecting betterproto<2.0.0\r\n",
      "  Downloading betterproto-1.2.5.tar.gz (26 kB)\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numba>=0.54 in /opt/conda/lib/python3.7/site-packages (from merlin-core->merlin-dataloader==0.0.2) (0.55.2)\r\n",
      "Collecting stringcase\r\n",
      "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting grpclib\r\n",
      "  Downloading grpclib-0.4.3.tar.gz (62 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: partd>=0.3.10 in /opt/conda/lib/python3.7/site-packages (from dask>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (1.3.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.7/site-packages (from dask>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (6.0)\r\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from dask>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (2.1.0)\r\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from dask>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (2022.8.2)\r\n",
      "Requirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from dask>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (0.11.2)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from distributed>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (3.1.2)\r\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /opt/conda/lib/python3.7/site-packages (from distributed>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (2.4.0)\r\n",
      "Requirement already satisfied: tornado>=5 in /opt/conda/lib/python3.7/site-packages (from distributed>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (6.1)\r\n",
      "Requirement already satisfied: tblib>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (1.7.0)\r\n",
      "Requirement already satisfied: zict>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from distributed>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (2.2.0)\r\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (1.0.4)\r\n",
      "Requirement already satisfied: psutil>=5.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (5.9.1)\r\n",
      "Requirement already satisfied: click>=6.6 in /opt/conda/lib/python3.7/site-packages (from distributed>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (8.0.4)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from distributed>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (59.8.0)\r\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba>=0.54->merlin-core->merlin-dataloader==0.0.2) (0.38.1)\r\n",
      "Requirement already satisfied: numpy<1.23,>=1.18 in /opt/conda/lib/python3.7/site-packages (from numba>=0.54->merlin-core->merlin-dataloader==0.0.2) (1.21.6)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->merlin-core->merlin-dataloader==0.0.2) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core->merlin-dataloader==0.0.2) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core->merlin-dataloader==0.0.2) (2022.1)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-metadata>=1.2.0->merlin-core->merlin-dataloader==0.0.2) (1.56.3)\r\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /opt/conda/lib/python3.7/site-packages (from tensorflow-metadata>=1.2.0->merlin-core->merlin-dataloader==0.0.2) (0.15.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py<2.0.0,>=0.9->tensorflow-metadata>=1.2.0->merlin-core->merlin-dataloader==0.0.2) (1.15.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=6.6->distributed>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (4.13.0)\r\n",
      "Requirement already satisfied: locket in /opt/conda/lib/python3.7/site-packages (from partd>=0.3.10->dask>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (1.0.0)\r\n",
      "Requirement already satisfied: heapdict in /opt/conda/lib/python3.7/site-packages (from zict>=0.1.3->distributed>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (1.0.1)\r\n",
      "Collecting h2<5,>=3.1.0\r\n",
      "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: multidict in /opt/conda/lib/python3.7/site-packages (from grpclib->betterproto<2.0.0->merlin-core->merlin-dataloader==0.0.2) (6.0.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->distributed>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (2.1.1)\r\n",
      "Collecting hyperframe<7,>=6.0\r\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\r\n",
      "Collecting hpack<5,>=4.0\r\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click>=6.6->distributed>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (3.8.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click>=6.6->distributed>=2021.11.2->merlin-core->merlin-dataloader==0.0.2) (4.4.0)\r\n",
      "Building wheels for collected packages: merlin-dataloader, merlin-core, betterproto, grpclib, stringcase\r\n",
      "  Building wheel for merlin-dataloader (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for merlin-dataloader: filename=merlin_dataloader-0.0.2-py3-none-any.whl size=29204 sha256=514766102d691152ff61cd719e3ba82ddd023a572a179dc19c53da53a7186993\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/30/f3/00/80ac2c82293a7443be28f1bcf682cddfd7fdbcd6e105b3a3ab\r\n",
      "  Building wheel for merlin-core (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for merlin-core: filename=merlin_core-0.5.0-py3-none-any.whl size=109355 sha256=9276cebabd6f39f9204aa3a4f4e33fd8f4fb4689c1edd28e8bddc05280b25f7e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/19/62/598b031339ba3b38a0255bb275c8f8ee2a4917407416970837\r\n",
      "  Building wheel for betterproto (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for betterproto: filename=betterproto-1.2.5-py3-none-any.whl size=21998 sha256=4e6ccaa78442b6ddc2c30b036f814594153ca6393dc0d3717e37add20b9609f2\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/d5/d7/46/97b7ec73d54fb8fc70775837af159e34b4965eda3481c7e659\r\n",
      "  Building wheel for grpclib (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for grpclib: filename=grpclib-0.4.3-py3-none-any.whl size=77061 sha256=8a97b72cff85b40779b658d4c85216e053a7bae0fa0724cf45b57e22f250e4bd\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/53/7d/0c5c8970895a99d2211c22d751756e69f1ec8383651838b199\r\n",
      "  Building wheel for stringcase (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3587 sha256=376cc869e253f3a23044850866d906a760d059e6609f241c841fa906729fe91f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/86/ab/a3/a8fa7e0a07e80f547e03468c03827f8257f7339327986faed1\r\n",
      "Successfully built merlin-dataloader merlin-core betterproto grpclib stringcase\r\n",
      "Installing collected packages: stringcase, hyperframe, hpack, h2, grpclib, betterproto, merlin-core, merlin-dataloader\r\n",
      "Successfully installed betterproto-1.2.5 grpclib-0.4.3 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 merlin-core-0.5.0 merlin-dataloader-0.0.2 stringcase-1.2.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install merlin-dataloader==0.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "380acfd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:29:51.538797Z",
     "iopub.status.busy": "2023-03-20T03:29:51.538333Z",
     "iopub.status.idle": "2023-03-20T03:29:53.535236Z",
     "shell.execute_reply": "2023-03-20T03:29:53.533979Z"
    },
    "papermill": {
     "duration": 2.017195,
     "end_time": "2023-03-20T03:29:53.538031",
     "exception": false,
     "start_time": "2023-03-20T03:29:51.520836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from merlin.loader.torch import Loader "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce56786c",
   "metadata": {
    "papermill": {
     "duration": 0.014659,
     "end_time": "2023-03-20T03:29:53.568268",
     "exception": false,
     "start_time": "2023-03-20T03:29:53.553609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can read data directly from the disk -- even better!\n",
    "\n",
    "Let's write our datasets to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5628759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:29:53.600384Z",
     "iopub.status.busy": "2023-03-20T03:29:53.599926Z",
     "iopub.status.idle": "2023-03-20T03:30:04.074697Z",
     "shell.execute_reply": "2023-03-20T03:30:04.072857Z"
    },
    "papermill": {
     "duration": 10.494272,
     "end_time": "2023-03-20T03:30:04.077837",
     "exception": false,
     "start_time": "2023-03-20T03:29:53.583565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pairs[:-10_000_000].to_pandas().to_parquet('train_pairs.parquet')\n",
    "train_pairs[-10_000_000:].to_pandas().to_parquet('valid_pairs.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b81935c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:30:04.112094Z",
     "iopub.status.busy": "2023-03-20T03:30:04.111256Z",
     "iopub.status.idle": "2023-03-20T03:30:05.914255Z",
     "shell.execute_reply": "2023-03-20T03:30:05.912967Z"
    },
    "papermill": {
     "duration": 1.823278,
     "end_time": "2023-03-20T03:30:05.917683",
     "exception": false,
     "start_time": "2023-03-20T03:30:04.094405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chronus/miniforge3/envs/ml/lib/python3.10/site-packages/merlin/dtypes/mappings/tf.py:52: UserWarning: Tensorflow dtype mappings did not load successfully due to an error: No module named 'tensorflow'\n",
      "  warn(f\"Tensorflow dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "/Users/chronus/miniforge3/envs/ml/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'\n",
      "  warn(f\"Triton dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "/Users/chronus/miniforge3/envs/ml/lib/python3.10/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from merlin.loader.torch import Loader \n",
    "from merlin.io import Dataset\n",
    "\n",
    "train_ds = Dataset('train_pairs.parquet')\n",
    "train_dl_merlin = Loader(train_ds, 65536, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "187c32de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:30:05.952271Z",
     "iopub.status.busy": "2023-03-20T03:30:05.951856Z",
     "iopub.status.idle": "2023-03-20T03:30:46.024910Z",
     "shell.execute_reply": "2023-03-20T03:30:46.023113Z"
    },
    "papermill": {
     "duration": 40.107929,
     "end_time": "2023-03-20T03:30:46.042836",
     "exception": false,
     "start_time": "2023-03-20T03:30:05.934907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.7 s, sys: 4.78 s, total: 16.5 s\n",
      "Wall time: 18.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for batch, _ in train_dl_merlin:\n",
    "    aid1, aid2 = batch['aid'], batch['aid_next']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b2aad5",
   "metadata": {
    "papermill": {
     "duration": 0.015913,
     "end_time": "2023-03-20T03:30:46.075190",
     "exception": false,
     "start_time": "2023-03-20T03:30:46.059277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "That is much better ðŸ™‚. Let's train our matrix factorization model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cf09a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:30:46.109998Z",
     "iopub.status.busy": "2023-03-20T03:30:46.109026Z",
     "iopub.status.idle": "2023-03-20T03:30:46.368249Z",
     "shell.execute_reply": "2023-03-20T03:30:46.367118Z"
    },
    "papermill": {
     "duration": 0.279471,
     "end_time": "2023-03-20T03:30:46.371205",
     "exception": false,
     "start_time": "2023-03-20T03:30:46.091734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chronus/miniforge3/envs/ml/lib/python3.10/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, n_aids, n_factors):\n",
    "        super().__init__()\n",
    "        self.aid_factors = nn.Embedding(n_aids, n_factors, sparse=True)\n",
    "        \n",
    "    def forward(self, aid1, aid2):\n",
    "        aid1 = self.aid_factors(aid1)\n",
    "        aid2 = self.aid_factors(aid2)\n",
    "        \n",
    "        return (aid1 * aid2).sum(dim=1)\n",
    "    \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "valid_ds = Dataset('valid_pairs.parquet')\n",
    "valid_dl_merlin = Loader(valid_ds, 65536, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "754aa584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:30:46.403902Z",
     "iopub.status.busy": "2023-03-20T03:30:46.403221Z",
     "iopub.status.idle": "2023-03-20T03:30:46.982684Z",
     "shell.execute_reply": "2023-03-20T03:30:46.981081Z"
    },
    "papermill": {
     "duration": 0.598751,
     "end_time": "2023-03-20T03:30:46.985326",
     "exception": false,
     "start_time": "2023-03-20T03:30:46.386575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import SparseAdam\n",
    "\n",
    "num_epochs=1\n",
    "lr=0.1\n",
    "\n",
    "model = MatrixFactorization(cardinality_aids+1, 32)\n",
    "optimizer = SparseAdam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f07daa20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T03:30:47.020872Z",
     "iopub.status.busy": "2023-03-20T03:30:47.019637Z",
     "iopub.status.idle": "2023-03-20T04:01:06.572210Z",
     "shell.execute_reply": "2023-03-20T04:01:06.570640Z"
    },
    "papermill": {
     "duration": 1819.587648,
     "end_time": "2023-03-20T04:01:06.589104",
     "exception": false,
     "start_time": "2023-03-20T03:30:47.001456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01: * TrainLoss 1.178  * Accuracy 0.687\n",
      "CPU times: user 8min 29s, sys: 10min 32s, total: 19min 1s\n",
      "Wall time: 4min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch, _ in train_dl_merlin:\n",
    "        model.train()\n",
    "        losses = AverageMeter('Loss', ':.4e')\n",
    "            \n",
    "        aid1, aid2 = batch['aid'], batch['aid_next']\n",
    "        output_pos = model(aid1, aid2)\n",
    "        output_neg = model(aid1, aid2[torch.randperm(aid2.shape[0])])\n",
    "        \n",
    "        output = torch.cat([output_pos, output_neg])\n",
    "        targets = torch.cat([torch.ones_like(output_pos), torch.zeros_like(output_pos)])\n",
    "        loss = criterion(output, targets)\n",
    "        losses.update(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        accuracy = AverageMeter('accuracy')\n",
    "        for batch, _ in valid_dl_merlin:\n",
    "            aid1, aid2 = batch['aid'], batch['aid_next']\n",
    "            output_pos = model(aid1, aid2)\n",
    "            output_neg = model(aid1, aid2[torch.randperm(aid2.shape[0])])\n",
    "            accuracy_batch = torch.cat([output_pos.sigmoid() > 0.5, output_neg.sigmoid() < 0.5]).float().mean()\n",
    "            accuracy.update(accuracy_batch, aid1.shape[0])\n",
    "            \n",
    "    print(f'{epoch+1:02d}: * TrainLoss {losses.avg:.3f}  * Accuracy {accuracy.avg:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e913e7",
   "metadata": {
    "papermill": {
     "duration": 0.015129,
     "end_time": "2023-03-20T04:01:06.619561",
     "exception": false,
     "start_time": "2023-03-20T04:01:06.604432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's grab the embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cc23771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T04:01:06.651796Z",
     "iopub.status.busy": "2023-03-20T04:01:06.651367Z",
     "iopub.status.idle": "2023-03-20T04:01:06.657305Z",
     "shell.execute_reply": "2023-03-20T04:01:06.655947Z"
    },
    "papermill": {
     "duration": 0.025223,
     "end_time": "2023-03-20T04:01:06.659928",
     "exception": false,
     "start_time": "2023-03-20T04:01:06.634705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = model.aid_factors.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b6c54",
   "metadata": {
    "papermill": {
     "duration": 0.015714,
     "end_time": "2023-03-20T04:01:06.692095",
     "exception": false,
     "start_time": "2023-03-20T04:01:06.676381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And construct create the index for approximate nearest neighbor search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23d3df14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T04:01:06.726081Z",
     "iopub.status.busy": "2023-03-20T04:01:06.725671Z",
     "iopub.status.idle": "2023-03-20T04:01:31.208893Z",
     "shell.execute_reply": "2023-03-20T04:01:31.207462Z"
    },
    "papermill": {
     "duration": 24.504205,
     "end_time": "2023-03-20T04:01:31.211652",
     "exception": false,
     "start_time": "2023-03-20T04:01:06.707447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.3 s, sys: 1.03 s, total: 37.4 s\n",
      "Wall time: 14.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "index = AnnoyIndex(32, 'euclidean')\n",
    "for i, v in enumerate(embeddings):\n",
    "    index.add_item(i, v)\n",
    "    \n",
    "index.build(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58f488b",
   "metadata": {
    "papermill": {
     "duration": 0.017703,
     "end_time": "2023-03-20T04:01:31.245303",
     "exception": false,
     "start_time": "2023-03-20T04:01:31.227600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now for any `aid`, we can find its nearest neighbor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36fcc5a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T04:01:31.281423Z",
     "iopub.status.busy": "2023-03-20T04:01:31.280035Z",
     "iopub.status.idle": "2023-03-20T04:01:31.288843Z",
     "shell.execute_reply": "2023-03-20T04:01:31.287980Z"
    },
    "papermill": {
     "duration": 0.028435,
     "end_time": "2023-03-20T04:01:31.291159",
     "exception": false,
     "start_time": "2023-03-20T04:01:31.262724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[123, 539087, 1007778, 405376, 605734, 704554, 57551, 1115280, 974562, 324669]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.get_nns_by_item(123, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0469359e",
   "metadata": {
    "papermill": {
     "duration": 0.015288,
     "end_time": "2023-03-20T04:01:31.322581",
     "exception": false,
     "start_time": "2023-03-20T04:01:31.307293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's create a submission! ðŸ™‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6843cbf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T04:01:31.357076Z",
     "iopub.status.busy": "2023-03-20T04:01:31.356258Z",
     "iopub.status.idle": "2023-03-20T04:05:14.255174Z",
     "shell.execute_reply": "2023-03-20T04:05:14.253854Z"
    },
    "papermill": {
     "duration": 222.919672,
     "end_time": "2023-03-20T04:05:14.258369",
     "exception": false,
     "start_time": "2023-03-20T04:01:31.338697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "sample_sub = pd.read_csv('/Users/chronus/Data/code/Git-repo/machine learning/sample_submission.csv')\n",
    "\n",
    "session_types = ['clicks', 'carts', 'orders']\n",
    "test_session_AIDs = test.to_pandas().reset_index(drop=True).groupby('session')['aid'].apply(list)\n",
    "test_session_types = test.to_pandas().reset_index(drop=True).groupby('session')['type'].apply(list)\n",
    "\n",
    "labels = []\n",
    "\n",
    "type_weight_multipliers = {0: 1, 1: 6, 2: 3}\n",
    "for AIDs, types in zip(test_session_AIDs, test_session_types):\n",
    "    if len(AIDs) >= 20:\n",
    "        # if we have enough aids (over equals 20) we don't need to look for candidates! we just use the old logic\n",
    "        weights=np.logspace(0.1,1,len(AIDs),base=2, endpoint=True)-1\n",
    "        aids_temp=defaultdict(lambda: 0)\n",
    "        for aid,w,t in zip(AIDs,weights,types): \n",
    "            aids_temp[aid]+= w * type_weight_multipliers[t]\n",
    "            \n",
    "        sorted_aids=[k for k, v in sorted(aids_temp.items(), key=lambda item: -item[1])]\n",
    "        labels.append(sorted_aids[:20])\n",
    "    else:\n",
    "        # here we don't have 20 aids to output -- we will use approximate nearest neighbor search and our embeddings\n",
    "        # to generate candidates!\n",
    "        AIDs = list(dict.fromkeys(AIDs[::-1]))\n",
    "        \n",
    "        # let's grab the most recent aid\n",
    "        most_recent_aid = AIDs[0]\n",
    "        \n",
    "        # and look for some neighbors!\n",
    "        nns = index.get_nns_by_item(most_recent_aid, 21)[1:]\n",
    "                        \n",
    "        labels.append((AIDs+nns)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f3cb9",
   "metadata": {
    "papermill": {
     "duration": 0.0159,
     "end_time": "2023-03-20T04:05:14.291145",
     "exception": false,
     "start_time": "2023-03-20T04:05:14.275245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's now pull it all together and write to a file,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "581aae6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T04:05:14.326168Z",
     "iopub.status.busy": "2023-03-20T04:05:14.325332Z",
     "iopub.status.idle": "2023-03-20T04:05:50.313605Z",
     "shell.execute_reply": "2023-03-20T04:05:50.312217Z"
    },
    "papermill": {
     "duration": 36.009052,
     "end_time": "2023-03-20T04:05:50.316811",
     "exception": false,
     "start_time": "2023-03-20T04:05:14.307759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_as_strings = [' '.join([str(l) for l in lls]) for lls in labels]\n",
    "\n",
    "predictions = pd.DataFrame(data={'session_type': test_session_AIDs.index, 'labels': labels_as_strings})\n",
    "\n",
    "prediction_dfs = []\n",
    "\n",
    "for st in session_types:\n",
    "    modified_predictions = predictions.copy()\n",
    "    modified_predictions.session_type = modified_predictions.session_type.astype('str') + f'_{st}'\n",
    "    prediction_dfs.append(modified_predictions)\n",
    "\n",
    "submission = pd.concat(prediction_dfs).reset_index(drop=True)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d46a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-18T02:49:02.940858Z",
     "iopub.status.busy": "2022-11-18T02:49:02.940358Z",
     "iopub.status.idle": "2022-11-18T02:49:02.973867Z",
     "shell.execute_reply": "2022-11-18T02:49:02.972223Z",
     "shell.execute_reply.started": "2022-11-18T02:49:02.940760Z"
    },
    "papermill": {
     "duration": 0.016002,
     "end_time": "2023-03-20T04:05:50.350395",
     "exception": false,
     "start_time": "2023-03-20T04:05:50.334393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And we are done!\n",
    "\n",
    "\n",
    "**If you like this notebook, please smash the upvote button! Thank you! ðŸ˜Š**\n",
    "\n",
    "There are many ways in which this can be expanded:\n",
    "* we can train on the GPU\n",
    "* we can train for longer\n",
    "* maybe we would get better results if we were to filter our train data by type?\n",
    "* should we train only on adjacent aids? maybe we should expand the neighborhood we train on\n",
    "\n",
    "We can keep asking ourselves many questions like this ðŸ™‚ Now we have a framework to start answering them!\n",
    "\n",
    "Thank you for reading! Happy Kaggling! ðŸ™Œ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3067.511911,
   "end_time": "2023-03-20T04:05:53.703976",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-20T03:14:46.192065",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
